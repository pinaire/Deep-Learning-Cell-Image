{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f405d189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[161.,   6.,   6.],\n",
      "        [  5., 165.,   0.],\n",
      "        [  5.,   0., 165.]])\n",
      "accuracy: 0.9571150097465887\n",
      "sum of elements: 513.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import xlsxwriter\n",
    "\n",
    "\n",
    "#data directory\n",
    "data_dir = r'C:\\Users\\alexp\\Desktop\\MCF7_classification\\viable_apop\\traintest\\Vtest'\n",
    "#data_dir = r'C:\\Users\\alexp\\Documents\\MATLAB\\Dr_Hu_Projects\\Clustering\\relabel\\new_class\\Vtest'\n",
    "#data_dir = r'C:\\Users\\pinai\\OneDrive - East Carolina University\\Desktop\\MCF7_classification\\viable_apop\\traintest\\Vtest'\n",
    "#data_dir = r'C:\\Users\\pinai\\OneDrive - East Carolina University\\Documents\\MATLAB\\Dr_Hu_Projects\\Clustering\\relabel\\new_class\\Vtest'\n",
    "\n",
    "num_classes = 3\n",
    "resize = 160\n",
    "totalin = 5120\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(resize),\n",
    "                                      transforms.\n",
    "                                      transforms.ToTensor(),\n",
    "                                      ]) \n",
    "\n",
    "test_data = datasets.ImageFolder(data_dir,\n",
    "                    transform=test_transforms)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data)\n",
    "\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "def conv1x1(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=1, \n",
    "                     stride=stride, padding=0, bias=False)\n",
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "#DINet-R2 with feature extraction\n",
    "z_stor = torch.zeros(len(test_data), totalin)\n",
    "ft = 0\n",
    "# ResNet\n",
    "class ResNet(nn.Module):\n",
    "\tdef __init__(self, block, layers, num_classes = num_classes):\n",
    "\t\tsuper(ResNet, self).__init__()\n",
    "\t\tself.in_channels = 16\n",
    "\t\tself.conv = conv3x3(3, 16)\n",
    "\t\tself.bn = nn.BatchNorm2d(16)\n",
    "\t\tself.relu = nn.ReLU(inplace=True)\n",
    "\t\tself.layer1 = self.make_layer(block, 32, layers[0])\n",
    "\t\tself.layer2 = self.make_layer(block, 64, layers[1])\n",
    "\t\tself.layer3 = self.make_layer(block, 128, layers[2])\n",
    "\t\tself.pool = nn.AvgPool2d(3, stride = 2)\n",
    "#\t\tself.pool2 = nn.AvgPool2d(2, stride = 1)\n",
    "\t\tself.conv4 = conv3x3(128, 256)\n",
    "\t\tself.bn4 = nn.BatchNorm2d(256)\n",
    "\t\tself.fc1 = nn.Linear(totalin, num_classes)\n",
    "\t\tself.softmax = nn.Softmax(dim=1)\n",
    "       \n",
    "\tdef make_layer(self, block, out_channels, blocks, stride=1):\n",
    "\t\tdownsample = None\n",
    "\t\tif (stride != 1) or (self.in_channels != out_channels):\n",
    "\t\t\tdownsample = nn.Sequential(\n",
    "\t\t\t\tconv1x1(self.in_channels, out_channels, stride=stride),\n",
    "\t\t\t\tnn.BatchNorm2d(out_channels))\n",
    "\t\tlayers = []\n",
    "\t\tlayers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "\t\tself.in_channels = out_channels\n",
    "\t\tfor i in range(1, blocks):\n",
    "\t\t\tlayers.append(block(out_channels, out_channels))\n",
    "\t\treturn nn.Sequential(*layers)\n",
    "\t\t\t\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tout = self.pool(x)\n",
    "\t\t#print(out.size())\n",
    "\t\tout = self.conv(out)\n",
    "\t\tout = self.bn(out)\n",
    "\t\tout = self.relu(out)\n",
    "\t\tout = self.pool(out)\n",
    "\t\t#print(out.size())\n",
    "\t\tout = self.layer1(out)\n",
    "#\t\tout = self.pool2(out)\n",
    "\t\t#print(out.size())\n",
    "\t\tout = self.layer2(out)\n",
    "\t\t#print(out.size())\n",
    "\t\tout = self.pool(out)\n",
    "\t\t#print(out.size())\n",
    "\t\tout = self.layer3(out)\n",
    "\t\t#print(out.size())\n",
    "\t\tout = self.pool(out)\n",
    "\t\t#print(out.size())\n",
    "\t\tout = self.conv4(out)\n",
    "\t\tout = self.bn4(out)\n",
    "\t\tout = self.relu(out)\n",
    "\t\tout = self.pool(out)\n",
    "#\t\tprint(out.size())\n",
    "\t\tout = out.view(out.size(0), -1)\n",
    "\n",
    "\t\t#feature extraction\n",
    "\t\timgg = out[0]\n",
    "\t\tfor ft in range(totalin):\n",
    "\t\t\tfox = imgg[ft]\n",
    "\t\t\tz_stor[steps-1, ft] = z_stor[steps-1, ft] + fox\n",
    "\t\t\t#print(steps)\n",
    "\n",
    "\t\tout = self.fc1(out)\n",
    "\t\tout = self.softmax(out)\n",
    "\t\treturn out\n",
    "\n",
    "\n",
    "#torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load('ResNet.pth')\n",
    "model\n",
    "\n",
    "#testing the model and extracting labels\n",
    "with torch.no_grad():\n",
    "    conf_table = torch.zeros(num_classes, num_classes)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    lbl_stor = torch.zeros(len(test_loader))\n",
    "    name_stor = []\n",
    "    steps = 0\n",
    "    model.eval()\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        steps += 1\n",
    "        img_name = test_data.imgs[steps-1]\n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        lbl_stor[steps-1] = lbl_stor[steps-1] + prediction\n",
    "        name_stor.append(img_name)\n",
    "        total += labels.size(0)\n",
    "        correct += (prediction == labels).sum().item()\n",
    "        accuracy = correct/total\n",
    "\n",
    "        #confusion matrix with accuracy results\n",
    "        for p, t in zip(prediction.view(-1), labels.view(-1)):\n",
    "                conf_table[p.long(), t.long()] += 1\n",
    "                confusion_matrix = torch.round(conf_table) \n",
    "                conf_sum = torch.sum(confusion_matrix)\n",
    "\n",
    "\n",
    "print(confusion_matrix)\n",
    "print(\"accuracy: {}\".format(accuracy))\n",
    "print(\"sum of elements: {}\".format(conf_sum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ed135",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5705c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grpno = 5\n",
    "\n",
    "#building a feature and label matrix for each cell class\n",
    "znlbl = torch.zeros(len(test_loader), totalin + 1, num_classes)\n",
    "\n",
    "for rw, ZZ in enumerate(z_stor):\n",
    "\tlbl = lbl_stor[rw]\n",
    "\tlbl = int(lbl.item())\n",
    "\tznlbl[rw,0,lbl] = znlbl[rw,0,lbl] + rw\n",
    "\tznlbl[rw,1:,lbl] = znlbl[rw,1:,lbl] + ZZ\n",
    "\n",
    "znlbl = znlbl.detach().numpy()\n",
    "\n",
    "znlbl0 = znlbl[:,:,0]\n",
    "znlbl_0 = znlbl0[np.sum( np.absolute(znlbl0), 1) != 0]\n",
    "\n",
    "znlbl1 = znlbl[:,:,1]\n",
    "znlbl_1 = znlbl1[np.sum( np.absolute(znlbl1), 1) != 0]\n",
    "\n",
    "znlbl2 = znlbl[:,:,2]\n",
    "znlbl_2 = znlbl2[np.sum( np.absolute(znlbl2), 1) != 0]\n",
    "\n",
    "zlabels = [znlbl_0,znlbl_1,znlbl_2]\n",
    "\n",
    "#matching the path, class/label, and features to organize the images\n",
    "lbl=-1\n",
    "for xxx in zlabels:\n",
    "    lbl=lbl+1\n",
    "\n",
    "    claspath = []\n",
    "    nosupaths = []\n",
    "    znosupp = []\n",
    "    zclass = []\n",
    "    for igg, zzz in enumerate(xxx):\n",
    "    \n",
    "    \tnsid = xxx[igg,0]\n",
    "    \tnosupimg = name_stor[int(nsid)]\n",
    "    \n",
    "    \tif lbl_stor[int(nsid)] == lbl and name_stor[int(nsid)][1] == lbl:\n",
    "    \t\tclaspath.append(nosupimg)\n",
    "    \t\tzclass.append(zzz[1:])\n",
    "    \n",
    "    \telse:\n",
    "    \t\tnosupaths.append(nosupimg)\n",
    "    \t\tznosupp.append(zzz[1:])\n",
    "    \n",
    "    #building a dat file of the correctly classified cells\n",
    "    suppbook = []\n",
    "    for rrw, vls in enumerate(zclass):\n",
    "            \n",
    "        rpath = claspath[rrw][0]\n",
    "        supclass = int(lbl)\n",
    "        vlis = vls.tolist()\n",
    "            \n",
    "        ptclaf = [rpath, supclass] + vlis\n",
    "        suppbook.append(ptclaf)\n",
    "        newbook = np.reshape(suppbook, [len(suppbook), totalin+2])\n",
    "        \n",
    "    #formm = len(suppbook)*[(totalin+2)*['%s']]\n",
    "    np.savetxt(r'C:\\Users\\alexp\\Documents\\MATLAB\\Dr_Hu_Projects\\Clustering\\relabel\\supp\\resupp_%d_%d.dat' %(grpno, lbl), newbook, delimiter = ',', fmt='%s')\n",
    "    #np.savetxt(r'C:\\Users\\pinai\\OneDrive - East Carolina University\\Documents\\MATLAB\\Dr_Hu_Projects\\Clustering\\relabel\\supp\\resupp_%d_%d.dat' %(grpno, via_apopnum), newbook, delimiter = ',', fmt='%s')\n",
    "        \n",
    "    #building an dat file with the incorrectly classified cells\n",
    "    nosuppbook = [];\n",
    "    for rrw, vls in enumerate(znosupp):\n",
    "        \n",
    "        rpath = nosupaths[rrw][0]\n",
    "        orig_class = int(nosupaths[rrw][1])\n",
    "        vlis = vls.tolist()\n",
    "            \n",
    "        ptclaf = [rpath, orig_class] + vlis\n",
    "        nosuppbook.append(ptclaf)\n",
    "        nobook = np.reshape(nosuppbook, [len(nosuppbook), totalin+2])\n",
    "        \n",
    "        #np.savetxt(r'C:\\Users\\pinai\\OneDrive - East Carolina University\\Documents\\MATLAB\\Dr_Hu_Projects\\Clustering\\relabel\\nosupp\\renosupp_%d_%d.dat' %(grpno, via_apopnum), nosuppbook, delimiter = ',', fmt='%s')\n",
    "    np.savetxt(r'C:\\Users\\alexp\\Documents\\MATLAB\\Dr_Hu_Projects\\Clustering\\relabel\\nosupp\\renosupp_%d_%d.dat' %(grpno, lbl), nosuppbook, delimiter = ',', fmt='%s')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00d3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
